{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class MLP:\n",
    "    \n",
    "    def __init__(self,*neurons):\n",
    "        self.layers = len(neurons)\n",
    "        self.neuPerL = [n for n in neurons]\n",
    "    \n",
    "    def setWeights(self,init):\n",
    "        if init == 'SND':\n",
    "            self.weights = [float(np.random.randn(1)) for l in range(self.layers-1)]\n",
    "        elif init == 'Uniform':\n",
    "            self.weights = [float(np.random.rand(1)) for l in range(self.layers-1)]\n",
    "        elif init == 'LeCun':\n",
    "            self.weights = [float(np.random.normal(0,1/np.sqrt(self.neuPerL[l]),1)) for l in range(self.layers-1)]\n",
    "        self.W_Hist = [self.weights]\n",
    "        self.LastChange = [0,0]\n",
    "  \n",
    "              \n",
    "    def tanh(self,x):\n",
    "        #return 1/(1+np.exp(-x))\n",
    "        return 1.7159 * np.tanh(2/3 * x)\n",
    "            \n",
    "    def der(self,x):\n",
    "        #return np.exp(x)/(np.exp(x)+1)**2\n",
    "        return 1.14393 * 1/np.cosh(2*x/3)**2\n",
    "    \n",
    "    def forward(self,inp):\n",
    "        self.activation = [inp]\n",
    "        for l in range(self.layers-1):\n",
    "            self.activation.append(self.tanh(np.dot(self.activation[-1],self.weights[l])))       \n",
    "             \n",
    "    def sgd(self,LR,epochs,mom,data,targ):\n",
    "        # Implements Stochastic Gradient Descent\n",
    "        self.LR = LR\n",
    "        self.mom = mom\n",
    "        p = np.zeros([epochs+1])\n",
    "        p[0] = self.test(data,targ)\n",
    "        for epoch in range(epochs):\n",
    "            for sample,target in zip(data,targ):\n",
    "                self.forward(sample)   \n",
    "                # Compute errors\n",
    "                self.deltas = [(self.activation[-1] - target) * self.der(np.dot(self.activation[-2],self.weights[-1]))]\n",
    "                for l in range(len(self.weights)-1):\n",
    "                    self.deltas.append(self.der(np.dot(self.activation[-3-l],self.weights[-2-l])) * self.weights[-1-l]*self.deltas[-1-l])\n",
    "                self.deltas = list(reversed(self.deltas))\n",
    "                \n",
    "                # Adapt weights\n",
    "                self.adaptWeights()   \n",
    "            self.LR = 0.99 * self.LR # Decaying LR\n",
    "            p[epoch+1] = self.test(data,targ)\n",
    "        return p\n",
    "            \n",
    "    def batch_gd(self,LR,epochs,mom,data,targets):\n",
    "        # Implements Batch Gradient Descent\n",
    "        # DOESNT WORK PROPERLY FOR SOEM REASON!!\n",
    "        p = np.zeros([epochs+1])\n",
    "        self.mom = mom\n",
    "        self.LR = LR\n",
    "        for epoch in range(epochs):\n",
    "            activity = np.zeros([len(data),self.layers])\n",
    "            for ind,sample in enumerate(data):\n",
    "                self.forward(sample) \n",
    "                activity[ind,:] = self.activation\n",
    "            loss = np.mean(activity[:,-1] - targets) \n",
    "            self.deltas = [loss * self.der(np.mean(activity[:,-2])*self.weights[-1])]\n",
    "            for l in range(len(self.weights)-1):\n",
    "                self.deltas.append(self.der(np.mean(activity[:,-3-l])*self.weights[-2-l]) * self.weights[-1-l]*self.deltas[-1-l])\n",
    "            self.deltas = list(reversed(self.deltas))\n",
    "            self.adaptWeights()\n",
    "            p[epoch+1] = self.test(data,targets)\n",
    "            self.LR = 0.99 * self.LR\n",
    "        return p\n",
    "    \n",
    "    def adaptWeights(self):\n",
    "        #print('w_vorrher', self.weights)\n",
    "        for l in range(len(self.weights)):\n",
    "            #print('d',self.deltas[l], 'mom',self.mom * self.W_Hist[-1][l],'a', self.activation[l],'adapt',self.LR * self.deltas[l] * self.activation[l] + self.mom * self.W_Hist[-1][l])\n",
    "            tmp = self.LR * self.deltas[l] * self.activation[l] + self.mom * self.LastChange[l]\n",
    "            self.weights[l] = self.weights[l] - tmp\n",
    "            self.LastChange[l] = tmp\n",
    "        self.W_Hist.append(self.weights)\n",
    "        #print('w_nach',self.weights)\n",
    "        \n",
    "    def test(self,data,targ):\n",
    "        correct = 0\n",
    "        for sample,target in zip(data,targ):\n",
    "            self.forward(sample)\n",
    "            correct += 1 if round(self.activation[-1]) == target else 0\n",
    "        return 100*correct/len(data)\n",
    "    \n",
    "\n",
    "    def getMSE(self, data, label):\n",
    "        errors = []\n",
    "        for ind,sample in enumerate(data):\n",
    "            self.forward(sample)\n",
    "            errors.append((self.activation[-1]-label[ind])**2)\n",
    "        return np.mean(errors)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and normalize Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampleSize = 30\n",
    "np.random.seed(1)\n",
    "cats = np.random.normal(25,5,sampleSize)\n",
    "dogs = np.random.normal(45,15,sampleSize)\n",
    "\n",
    "\n",
    "data = np.append(cats,dogs)\n",
    "data = (data-np.mean(data)) / np.std(data)\n",
    "t_c = -1 * np.ones([sampleSize])\n",
    "t_d = np.ones([sampleSize])\n",
    "targets = np.append(t_c,t_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Model Hyperparamter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight_init = ['Uniform','SND', 'LeCun']\n",
    "LR = 0.2\n",
    "epochs = 200\n",
    "momentum = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Call this Method to evaluate the performance of the network\n",
    "# Call it with True adds Momentum, calling it with False leaves it out\n",
    "def evaluate(mom):\n",
    "    perf = np.zeros([2*len(weight_init),epochs+1])\n",
    "    for ind,w in enumerate(weight_init):\n",
    "        # SGD\n",
    "        net = MLP(1,1,1)\n",
    "        net.setWeights(w)\n",
    "        perf[ind,:] = net.sgd(LR,epochs,mom,data,targets)\n",
    "        plt.plot(np.arange(perf.shape[1]),perf[ind,:],label=['SGD',w])\n",
    "\n",
    "        # Batch\n",
    "        net2 = MLP(1,1,1)\n",
    "        net2.setWeights(w)\n",
    "        perf[ind+len(weight_init),:] = net2.batch_gd(LR,epochs,mom,data,targets)\n",
    "        plt.plot(np.arange(perf.shape[1]),perf[ind+len(weight_init),:],label=['Batch',w])\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.17),ncol=3, fancybox=True, shadow=True)\n",
    "    plt.show()\n",
    "    #print(net.W_Hist)\n",
    "\n",
    "    \n",
    "\n",
    "def plotErrorSurface(density, net1Hist, net2Hist):\n",
    "\tmlp = MLP(1,1,1)\n",
    "\tmlp.setWeights('LeCun')    \n",
    "\t#dh = DataHandle()\n",
    "\t#data, label = dh.returnLabledBoth()\n",
    "\tweightRange = np.linspace(-4, 4, density)\n",
    "\tW1, W2 = np.meshgrid(weightRange, weightRange)\n",
    "\tallMse = np.zeros(np.shape(W1))\n",
    "\tfor i in range(density):\n",
    "\t\tfor j in range(density):\n",
    "\t\t\tmlp.weights[0] = W1[i,j]\n",
    "\t\t\tmlp.weights[1] = W2[i,j]\n",
    "\t\t\tmse = mlp.getMSE(data, targets)\n",
    "\t\t\tallMse[i,j] = mse\n",
    "\t\n",
    "\tfig = plt.figure()\n",
    "\tax = fig.add_subplot(111, projection='3d')\n",
    "\t#cp = ax.plot_surface(np.reshape(allW1,(density, density)),np.reshape(allW2, (density, density)), np.reshape(allMse, (density, density)), cmap = plt.cm.coolwarm)\n",
    "\tcp = ax.plot_surface(W1, W2, allMse, cmap = plt.cm.coolwarm)\n",
    "\tplt.colorbar(cp)\n",
    "\tplt.show()\n",
    "\n",
    "\tnet1W1Hist = [timestep[0] for timestep in net1Hist]\n",
    "\tnet1W2Hist = [timestep[1] for timestep in net1Hist]\n",
    "\tnet2W1Hist = [timestep[0] for timestep in net2Hist]\n",
    "\tnet2W2Hist = [timestep[1] for timestep in net2Hist]\n",
    "\tplt.figure()\n",
    "\tcp = plt.contourf(W1, W2, allMse)\n",
    "\tplt.plot(net1W1Hist,net1W2Hist,c='black', label='stochastic')\n",
    "\tplt.plot(net2W1Hist,net2W2Hist,c='green', label='batch')\n",
    "\tplt.colorbar(cp)\n",
    "\tplt.legend()\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "evaluate(0) # Evaluate without Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "evaluate(momentum) # Evaluate with Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp1 = MLP(1,1,1)\n",
    "mlp1.setWeights('LeCun')    \n",
    "mlp2 = MLP(1,1,1)\n",
    "mlp2.setWeights('LeCun')    \n",
    "mlp1.sgd(LR,epochs,decay,data,targets)\n",
    "mlp2.batch_gd(LR,epochs,decay,data,targets)\n",
    "\n",
    "plotErrorSurface(200,mlp1.W_Hist,mlp2.W_Hist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
